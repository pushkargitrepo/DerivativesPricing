{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64996d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = Name of the excel file\n",
    "# s = Sheet Name within the excel file\n",
    "# r = Range of data which needs to be imported\n",
    "# d = Data object that needs to be sent while exporting back\n",
    "\n",
    "def import_excel(n,s,r):\n",
    "    import xlwings as xw\n",
    "    wb = xw.Book(n)\n",
    "    sheet = wb.sheets[s]\n",
    "    data = sheet.range(r).value\n",
    "    return data \n",
    "\n",
    "def export_excel(n,s,r,d):\n",
    "    import xlwings as xw\n",
    "    wb = xw.Book(n)\n",
    "    sheet = wb.sheets[s]\n",
    "    sheet.range(r).value = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539a2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = import_excel('FRTB Data.xlsx','USDIRS','B3:D21')\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e794938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt = Date on which operation is to be performed\n",
    "#cal1 = Country of Calendar 1, For USA pass argument US\n",
    "#cal2 = Country of Calendar 2, For India pass argument IN .. This is an optional argument\n",
    "# At present this function suports a max of 2 calendars only for MFBD\n",
    "\n",
    "def mfbd(dt,cal1, cal2=\"NIL\"):\n",
    "    from datetime import date\n",
    "    from datetime import timedelta\n",
    "    import holidays\n",
    "    direction = 1\n",
    "    calendar1 = holidays.country_holidays(cal1)\n",
    "    if cal2 == \"NIL\":\n",
    "        while dt.weekday() > 4 or dt in calendar1:\n",
    "            if dt.month == (dt+timedelta(days=1)).month - 1:\n",
    "                direction = -1\n",
    "            dt = dt + timedelta(days=1)*direction \n",
    "    else:\n",
    "        calendar2 = holidays.country_holidays(cal2)\n",
    "        while dt.weekday() > 4 or dt in calendar1 or dt in calendar2:\n",
    "            if dt.month == (dt+timedelta(days=1)).month - 1:\n",
    "                direction = -1\n",
    "            dt = dt + timedelta(days=1)*direction \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97031773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data,i=-1,p=1):\n",
    "    from datetime import date,timedelta\n",
    "    import holidays\n",
    "    import pandas as pd\n",
    "    #PricingDate = date.today() #Use todays date as the Pricing Date\n",
    "    PricingDate = date(2025,5,19) # For testing currently\n",
    "    SDate = mfbd(PricingDate + timedelta(days=2),'US') #Calculating the Spot Start Date\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['Tenor','Unit','Rate']\n",
    "    i = int(i)\n",
    "    if i>-1:\n",
    "        df.iat[i,1]=df.iat[i,1]+0.0001*p\n",
    "        \n",
    "    df['MatDate'] = SDate \n",
    "    df['PmtDate'] = SDate\n",
    "\n",
    "    #Populate Maturity Date and Payment Date adjusting for pay delay\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        if row['Unit']=='d':\n",
    "            df.at[index,'MatDate'] = mfbd(row['MatDate'] + pd.offsets.DateOffset(days=row['Tenor']),'US')\n",
    "        elif row['Unit']=='w':\n",
    "            df.at[index,'MatDate'] = mfbd(row['MatDate'] + pd.offsets.DateOffset(weeks=row['Tenor']),'US')\n",
    "        elif row['Unit']=='m':\n",
    "            df.at[index,'MatDate'] = mfbd(row['MatDate'] + pd.offsets.DateOffset(months=row['Tenor']),'US')\n",
    "        elif row['Unit']=='y':\n",
    "            df.at[index,'MatDate'] = mfbd(row['MatDate'] + pd.offsets.DateOffset(years=row['Tenor']),'US')\n",
    "        \n",
    "        df.at[index,'PmtDate'] = mfbd(df.at[index,'MatDate'] + pd.offsets.DateOffset(days=2),'US') #SOFR Swaps have 2 days Payment Delay\n",
    "    \n",
    "    df['MatDate'] = pd.to_datetime(df['MatDate']).dt.date # To remove hh:mm:ss from Date\n",
    "    df['PmtDate'] = pd.to_datetime(df['PmtDate']).dt.date\n",
    "    df['DC'] = df['PmtDate'].diff(periods=1) #Compute Periodic day counts\n",
    "    \n",
    "    for i in range(0,15):\n",
    "        df.at[i,'DC']= pd.to_timedelta(df.at[i,'PmtDate']-SDate) #Compute DC value from Start Date for tenors upto 1 year\n",
    "    \n",
    "    \n",
    "    df['DC'] = pd.to_numeric(df['DC'].dt.days)\n",
    "    df['DC']=df['DC']/360 #Since Daycount is Act/360 for USD SOFR\n",
    " \n",
    "    import numpy as np\n",
    "    df['DF'] = 1.000000\n",
    " \n",
    "    SDate = mfbd(SDate,'US')\n",
    "\n",
    "\n",
    "    #Just testing, delete later\n",
    "    #for index,row in df.iterrows():\n",
    "    #    df.at[index,'DF'] = 1/(pow(1+row['Rate'],row['Year']))\n",
    "\n",
    "\n",
    "    #Compute actual Curve DFs for USD SOFR\n",
    "    #The for loop is massively simplified to solve a linear system of equations. Will write a full document on how this is calculated later. \n",
    "    # For queries in the interim email pushkars@myyahoo.com \n",
    "    dfdccumprodsum = 0\n",
    "    for index,row in df.iterrows():\n",
    "        if index < 14:\n",
    "            df.at[index,'DF'] = 1/(1+df.at[index,'Rate']*df.at[index,'DC'])\n",
    "        else:\n",
    "            df.at[index,'DF'] = (1 - df.at[index,'Rate']*dfdccumprodsum)/(1+df.at[index,'Rate']*df.at[index,'DC'])\n",
    "            dfdccumprodsum = dfdccumprodsum + df.at[index,'DC']*df.at[index,'DF']\n",
    "\n",
    "    #Compute Zeros for USD SOFR\n",
    "    # Please note that zeros requires an assumption of the approach. Here we are going to try and match\n",
    "    # it with that of bloomberg by assuming continuous compounding\n",
    "    # Different systems implement this bit in a different manner\n",
    "\n",
    "\n",
    "    df['Zero']=1.000000\n",
    "    \n",
    "    for index,row in df.iterrows():\n",
    "        #p = pd.to_timedelta(df.at[index,'PmtDate']-df.at[index,'MatDate'])\n",
    "        #t = float(p.days)/365 + df.at[index,'Year']\n",
    "        t = (df.at[index,'PmtDate'] - SDate).days/365 #Note this implementation is slightly different and less accurate as its \n",
    "        #dividing by 365 to give years which will create issues especially as we cross leap years. Will update in future iterations\n",
    "        #print(t)\n",
    "        df.at[index,'Zero'] = np.log(1/df.at[index,'DF'])/t\n",
    "\n",
    "    #Add 1 as Discount Factor for Spot Date in the Discount Factors Data Frame for US Rates \n",
    "    df.loc[-1] = [0.0,\"w\",0.0,SDate,SDate,0,1.00000,0]\n",
    "    df.index = df.index+1\n",
    "    df = df.sort_index()\n",
    "    \n",
    "        \n",
    "    #print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2c07841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tenor Unit      Rate     MatDate     PmtDate        DC        DF      Zero\n",
      "0     0.0    w  0.000000  2025-05-21  2025-05-21  0.000000  1.000000  0.000000\n",
      "1     1.0    w  0.043083  2025-05-28  2025-05-30  0.025000  0.998924  0.043658\n",
      "2     2.0    w  0.043149  2025-06-04  2025-06-06  0.044444  0.998086  0.043707\n",
      "3     3.0    w  0.043179  2025-06-11  2025-06-13  0.063889  0.997249  0.043718\n",
      "4     1.0    m  0.043230  2025-06-23  2025-06-25  0.097222  0.995815  0.043739\n",
      "5     2.0    m  0.043284  2025-07-21  2025-07-23  0.175000  0.992482  0.043720\n",
      "6     3.0    m  0.043218  2025-08-21  2025-08-25  0.266667  0.988606  0.043568\n",
      "7     4.0    m  0.043149  2025-09-22  2025-09-24  0.350000  0.985123  0.043421\n",
      "8     5.0    m  0.042944  2025-10-21  2025-10-23  0.430556  0.981846  0.043143\n",
      "9     6.0    m  0.042668  2025-11-21  2025-11-24  0.519444  0.978317  0.042788\n",
      "10    7.0    m  0.042358  2025-12-22  2025-12-24  0.602778  0.975103  0.042407\n",
      "11    8.0    m  0.042030  2026-01-21  2026-01-23  0.686111  0.971971  0.042011\n",
      "12    9.0    m  0.041662  2026-02-23  2026-02-25  0.777778  0.968613  0.041571\n",
      "13   10.0    m  0.041370  2026-03-23  2026-03-25  0.855556  0.965816  0.041219\n",
      "14   11.0    m  0.041053  2026-04-21  2026-04-23  0.936111  0.962992  0.040843\n",
      "15   12.0    m  0.040750  2026-05-21  2026-05-26  1.027778  0.959802  0.040474\n",
      "16    2.0    y  0.037767  2027-05-21  2027-05-24  1.008333  0.927426  0.037517\n",
      "17    3.0    y  0.037051  2028-05-22  2028-05-24  1.016667  0.895086  0.036811\n",
      "18    4.0    y  0.037070  2029-05-21  2029-05-23  1.011111  0.862696  0.036847\n",
      "19    5.0    y  0.037380  2030-05-21  2030-05-23  1.013889  0.830086  0.037184\n"
     ]
    }
   ],
   "source": [
    "test=bootstrap(data)\n",
    "print(test)\n",
    "#This gives us the bootstrapped curve for USD SOFR which is the basis for all of our FX Discounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5894a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapfx(data,usdf,fcycode,divfactor=10000,i=-1,p=1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date,timedelta, datetime, time\n",
    "    import math \n",
    "    df=pd.DataFrame(data)\n",
    "    df.columns=['Tenor','Unit','Bid','Ask']\n",
    "    spotrate= (df.at[0,'Bid'] + df.at[0,'Ask'])/2\n",
    "    #df = df.drop(df.index[0]) #Drop the spot rate row\n",
    "    #df = df.reset_index(drop=True) #Reset index after dropping spot rate row\n",
    "   \n",
    "    df['OR']=spotrate + (df['Bid'] + df['Ask'])/ (2*divfactor) #Allows flexibility to use 100 for JPY and 10,000 by default for others\n",
    "    df.at[0,'OR']=spotrate  #Set the outright for spot rate row\n",
    "    #Set Pricing Date\n",
    "    PDate = date(2025,5,19)  #You can set it to desired pricing date\n",
    "    SDate = mfbd(PDate + timedelta(days=2),'US',fcycode) #Calculating the Spot Start Date basis code recieved \n",
    "    \n",
    "    #Generate Maturity Dates\n",
    "    df['Date'] = SDate\n",
    "    for index,row in df.iterrows():\n",
    "        if row['Unit']=='d':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(days=row['Tenor']),'US',fcycode)\n",
    "        elif row['Unit']=='w':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(weeks=row['Tenor']),'US',fcycode)\n",
    "        elif row['Unit']=='m':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(months=row['Tenor']),'US',fcycode)\n",
    "        elif row['Unit']=='y':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(years=row['Tenor']),'US',fcycode)\n",
    "\n",
    "\n",
    "    #This will require us to interpolate and we are creating a float column as we cant interpolate on dates directly\n",
    "    MyTime = time(0,0,0)\n",
    "    ref = pd.Timestamp.combine(SDate,MyTime)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Days']=(df['Date']-ref)/timedelta(days=1)\n",
    "    usdf['PmtDate'] = usdf['PmtDate'].astype(\"datetime64[ns]\")\n",
    "    usdf['Days']=(usdf['PmtDate']-datetime.combine(SDate,MyTime))/timedelta(days=1)\n",
    "    #print(usdf)\n",
    "    df['USDF']=np.interp(df['Days'],usdf['Days'],usdf['DF'])\n",
    "    if  fcycode == 'XECB' or fcycode == 'GB' or fcycode == 'AU':\n",
    "        df['FCYDF']=df['OR']*df['USDF']/spotrate\n",
    "    else:\n",
    "        df['FCYDF']=df['USDF']*spotrate/df['OR']    \n",
    "    \n",
    "    df['FCYYld']=(1/df['FCYDF']-1)*365/df['Days']\n",
    "    \n",
    "    df.at[0,'FCYYld'] = 0.0 #Override first yield with 0 as spot has no yield\n",
    "    \n",
    "    #This step overwrites the DFs and the Outrights with perturbed values if any\n",
    "    #i = int(i)\n",
    "    #if i>-1:\n",
    "    #    df.iat[i,6]=df.iat[i,6]+0.0001*p\n",
    "    #df['FCYDF']=1/(1+df['FCYYld']*df['Days']/365)\n",
    "    #df['OR']=spotrate *df['USDF']/df['FCYDF']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40e6d4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tenor Unit      Bid      Ask         OR       Date    Days      USDF  \\\n",
      "0     0.0    d   156.39   156.40  156.39500 2025-05-21     0.0  1.000000   \n",
      "1     1.0    d    -3.14    -3.13  156.36365 2025-05-22     1.0  0.999880   \n",
      "2     1.0    w   -11.39   -11.37  156.28120 2025-05-28     7.0  0.999163   \n",
      "3     2.0    w   -22.36   -22.35  156.17145 2025-06-04    14.0  0.998325   \n",
      "4     3.0    w   -33.00   -32.00  156.07000 2025-06-11    21.0  0.997488   \n",
      "5     1.0    m   -46.89   -45.82  155.93145 2025-06-23    33.0  0.996054   \n",
      "6     2.0    m   -98.50   -97.07  155.41715 2025-07-22    62.0  0.992601   \n",
      "7     3.0    m  -141.72  -140.48  154.98400 2025-08-21    92.0  0.989076   \n",
      "8     4.0    m  -181.81  -178.32  154.59435 2025-09-22   124.0  0.985355   \n",
      "9     5.0    m  -225.77  -225.38  154.13925 2025-10-21   153.0  0.982072   \n",
      "10    6.0    m  -263.36  -263.03  153.76305 2025-11-21   184.0  0.978648   \n",
      "11    7.0    m  -299.33  -299.08  153.40295 2025-12-22   215.0  0.975317   \n",
      "12    8.0    m  -337.26  -337.08  153.02330 2026-01-21   245.0  0.972180   \n",
      "13    9.0    m  -373.45  -373.33  152.66110 2026-02-24   279.0  0.968715   \n",
      "14   10.0    m  -409.47  -409.43  152.30050 2026-03-23   306.0  0.966015   \n",
      "15   11.0    m  -437.19  -437.18  152.02315 2026-04-21   335.0  0.963187   \n",
      "16   12.0    m  -468.55  -466.35  151.72050 2026-05-21   365.0  0.960285   \n",
      "17   15.0    m  -566.86  -561.54  150.75300 2026-08-21   457.0  0.952042   \n",
      "18   21.0    m  -728.19  -728.13  149.11340 2027-02-22   642.0  0.935542   \n",
      "19    2.0    y  -802.53  -802.21  148.37130 2027-05-21   730.0  0.927694   \n",
      "20    3.0    y -1135.00 -1113.00  145.15500 2028-05-22  1097.0  0.895262   \n",
      "21    4.0    y -1462.00 -1432.00  141.92500 2029-05-21  1461.0  0.862874   \n",
      "22    5.0    y -1789.00 -1750.00  138.70000 2030-05-21  1826.0  0.830265   \n",
      "\n",
      "       FCYDF    FCYYld  \n",
      "0   1.000000  0.000000  \n",
      "1   1.000081 -0.029534  \n",
      "2   0.999891  0.005698  \n",
      "3   0.999754  0.006404  \n",
      "4   0.999565  0.007560  \n",
      "5   0.999015  0.010908  \n",
      "6   0.998847  0.006799  \n",
      "7   0.998081  0.007628  \n",
      "8   0.996832  0.009355  \n",
      "9   0.996444  0.008514  \n",
      "10  0.995399  0.009169  \n",
      "11  0.994340  0.009663  \n",
      "12  0.993601  0.009595  \n",
      "13  0.992409  0.010007  \n",
      "14  0.991986  0.009636  \n",
      "15  0.990886  0.010022  \n",
      "16  0.989872  0.010232  \n",
      "17  0.987673  0.009968  \n",
      "18  0.981227  0.010877  \n",
      "19  0.977862  0.011320  \n",
      "20  0.964586  0.012216  \n",
      "21  0.950849  0.012914  \n",
      "22  0.936188  0.013625  \n"
     ]
    }
   ],
   "source": [
    "#Step 1 - Generating DFs from Excel\n",
    "data = import_excel('FRTB Data.xlsx','USDIRS','B3:D21')\n",
    "usdf=bootstrap(data)\n",
    "data = import_excel('FRTB Data.xlsx','FX','C2:f24')\n",
    "eurdf=bootstrapfx(data,usdf,'XECB') #XECB is the code for TARGET Calendar\n",
    "data = import_excel('FRTB Data.xlsx','FX','i2:l24')\n",
    "gbpdf=bootstrapfx(data,usdf,'GB')\n",
    "data = import_excel('FRTB Data.xlsx','FX','o2:r24')\n",
    "jpydf=bootstrapfx(data,usdf,'JP',100) #JPY has a 100 division factor for points\n",
    "print(jpydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "543f7f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouped Summary:\n",
      "Pair\n",
      "EURUSD    1.108455e+06\n",
      "GBPUSD    1.712367e+06\n",
      "USDJPY   -1.282894e+06\n",
      "Name: USD Delta, dtype: float64\n",
      "\n",
      "FRTB Capital Charge (Vanilla FX Only):\n",
      "\n",
      "Low correlation charge   : 233,458\n",
      "Medium correlation charge: 218,850\n",
      "High correlation charge  : 203,193\n",
      "FRTB FX Capital Charge   : 233,458\n"
     ]
    }
   ],
   "source": [
    "def get_delta_amount(row):\n",
    "    # If USD is the notional currency\n",
    "    if row['Not CCY'] == 'USD':\n",
    "        return row['vs CCY Amt']   # the other side is non-USD\n",
    "    # If USD is the vs currency\n",
    "    elif row['vs CCY'] == 'USD':\n",
    "        return row['CCY Amt']      # CCY Amt is non-USD\n",
    "    else:\n",
    "        return None  # or np.nan, or raise error\n",
    "\n",
    "#Step 2 - Importing Trade Data from Excel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = import_excel('FRTB Data.xlsx','FXTrades','a2:h5')\n",
    "tradeData=pd.DataFrame(data)\n",
    "tradeData.columns=['Sr No','Pair','Not CCY','CCY Amt','vs CCY', 'Rate','vs CCY Amt','Date']\n",
    "tradeData['Delta CCY']='USD'\n",
    "tradeData['Delta Amt'] = tradeData.apply(get_delta_amount, axis=1)\n",
    "\n",
    "curve_map = {\n",
    "    'EURUSD': eurdf,\n",
    "    'GBPUSD': gbpdf,\n",
    "    'USDJPY': jpydf\n",
    "}\n",
    "spot={\n",
    "    'EURUSD': eurdf.at[0,'OR'],\n",
    "    'GBPUSD': gbpdf.at[0,'OR'],\n",
    "    'USDJPY': jpydf.at[0,'OR']\n",
    "}\n",
    "tradeData['DF']=tradeData.apply(\n",
    "    lambda r: np.interp(\n",
    "        r['Date'].value,\n",
    "        curve_map[r['Pair']].sort_values('Date')['Date'].astype(np.int64).values,\n",
    "        curve_map[r['Pair']].sort_values('Date')['FCYDF'].values\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "tradeData['USD_Converted'] = tradeData.apply(\n",
    "    lambda r: r['Delta Amt'] * spot[r['Pair']] \n",
    "              if r['Pair'] in ('EURUSD', 'GBPUSD')\n",
    "              else r['Delta Amt'] / spot[r['Pair']],\n",
    "    axis=1\n",
    ")\n",
    "tradeData['USD Delta'] = tradeData['USD_Converted'] * tradeData['DF']\n",
    "\n",
    "grouped = tradeData.groupby('Pair')\n",
    "summary = grouped['USD Delta'].sum()\n",
    "#print(tradeData)\n",
    "print(\"\\nGrouped Summary:\")\n",
    "print(summary)\n",
    "\n",
    "#Step 3 - Compute the capital charge\n",
    "\n",
    "# Risk weight assumed to be 16%/sqrt(2) for major FX pairs as per BCBS guidelines\n",
    "rw = 0.16 / np.sqrt(2)\n",
    "x = summary.values\n",
    "#print(x)\n",
    "\n",
    "N = len(x)\n",
    "\n",
    "# Medium correlation = 0.60\n",
    "rho_med = 0.60\n",
    "corr_med = np.full((N, N), rho_med)\n",
    "np.fill_diagonal(corr_med, 1.0)\n",
    "\n",
    "# High correlation = min(1.0, 1.25*rho) = 0.75\n",
    "rho_high = min(1.0, 1.25*rho_med)\n",
    "corr_high = np.full((N, N), rho_high)\n",
    "np.fill_diagonal(corr_high, 1.0)\n",
    "\n",
    "# Low correlation = max(0, 0.75*rho) = 0.45\n",
    "rho_low = max(0, 0.75*rho_med)\n",
    "corr_low = np.full((N, N), rho_low)\n",
    "np.fill_diagonal(corr_low, 1.0)\n",
    "\n",
    "\n",
    "# Compute scenario charges\n",
    "charge_low  = rw * np.sqrt(x @ corr_low  @ x)\n",
    "charge_med  = rw * np.sqrt(x @ corr_med  @ x)\n",
    "charge_high = rw * np.sqrt(x @ corr_high @ x)\n",
    "\n",
    "# Final FRTB FX charge = max of all scenarios\n",
    "frtb_charge = max(charge_low, charge_med, charge_high)\n",
    "\n",
    "charge_low  = round(charge_low)\n",
    "charge_med  = round(charge_med)\n",
    "charge_high = round(charge_high)\n",
    "frtb_charge = round(frtb_charge)\n",
    "\n",
    "print(\"\\nFRTB Capital Charge (Vanilla FX Only):\\n\")\n",
    "print(f\"Low correlation charge   : {charge_low:,}\")\n",
    "print(f\"Medium correlation charge: {charge_med:,}\")\n",
    "print(f\"High correlation charge  : {charge_high:,}\")\n",
    "print(f\"FRTB FX Capital Charge   : {frtb_charge:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0337030a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
