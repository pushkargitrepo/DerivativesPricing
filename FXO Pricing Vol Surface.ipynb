{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4bae49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = Name of the excel file\n",
    "# s = Sheet Name within the excel file\n",
    "# r = Range of data which needs to be imported\n",
    "# d = Data object that needs to be sent while exporting back\n",
    "\n",
    "def import_excel(n,s,r):\n",
    "    import xlwings as xw\n",
    "    wb = xw.Book(n)\n",
    "    sheet = wb.sheets[s]\n",
    "    data = sheet.range(r).value\n",
    "    return data \n",
    "\n",
    "\n",
    "def export_excel(n,s,r,d):\n",
    "    import xlwings as xw\n",
    "    wb = xw.Book(n)\n",
    "    sheet = wb.sheets[s]\n",
    "    sheet.range(r).value = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fb321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt = Date on which operation is to be performed\n",
    "#cal1 = Country of Calendar 1, For USA pass argument US\n",
    "#cal2 = Country of Calendar 2, For India pass argument IN .. This is an optional argument\n",
    "# At present this function suports a max of 2 calendars only for MFBD\n",
    "\n",
    "def mfbd(dt,cal1, cal2=\"NIL\"):\n",
    "    from datetime import date\n",
    "    from datetime import timedelta\n",
    "    import holidays\n",
    "    direction = 1\n",
    "    calendar1 = holidays.country_holidays(cal1)\n",
    "    if cal2 == \"NIL\":\n",
    "        while dt.weekday() > 4 or dt in calendar1:\n",
    "            if dt.month == (dt+timedelta(days=1)).month - 1:\n",
    "                direction = -1\n",
    "            dt = dt + timedelta(days=1)*direction \n",
    "    else:\n",
    "        calendar2 = holidays.country_holidays(cal2)\n",
    "        while dt.weekday() > 4 or dt in calendar1 or dt in calendar2:\n",
    "            if dt.month == (dt+timedelta(days=1)).month - 1:\n",
    "                direction = -1\n",
    "            dt = dt + timedelta(days=1)*direction \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4eedb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volsurf(data,fcycode):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import holidays\n",
    "    from datetime import date,timedelta\n",
    "    import plotly.graph_objects as go\n",
    "    import nbformat\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['Tenor','Unit','ATM','25D RR','25D BF','10D RR','10D BF']\n",
    "    PricingDate = date.today()\n",
    "    SDate = mfbd(PricingDate + timedelta(days=2),'US',fcycode) #Calculating the Spot Date for EUR/USD\n",
    "    #Generate Maturity Dates\n",
    "    df['Date'] = SDate\n",
    "    for index,row in df.iterrows():\n",
    "        if row['Unit']=='d':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(days=row['Tenor']),'US',fcycode)\n",
    "        elif row['Unit']=='w':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(weeks=row['Tenor']),'US',fcycode)\n",
    "        elif row['Unit']=='m':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(months=row['Tenor']),'US',fcycode)\n",
    "        elif row['Unit']=='y':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(years=row['Tenor']),'US',fcycode)\n",
    "    \n",
    "    #We need to have some logic to price extreme vols here. I'm choosing flat for now\n",
    "    #An alternative is to use a multiplier of slope (Say 3 times) to extrapolate as long as vols ho higher than 10D / 90D \n",
    "    \n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['1D']= df['ATM'] + df['10D RR']/2 + df['10D BF']\n",
    "    df['10D']= df['ATM'] + df['10D RR']/2 + df['10D BF']\n",
    "    df['25D']= df['ATM'] + df['25D RR']/2 + df['25D BF']\n",
    "    df['50D']= df['ATM']\n",
    "    df['75D']= df['ATM'] - df['25D RR']/2 + df['25D BF']\n",
    "    df['90D']= df['ATM'] - df['10D RR']/2 + df['10D BF']\n",
    "    df['99D']= df['ATM'] - df['10D RR']/2 + df['10D BF']\n",
    "    \n",
    "    df = df.drop(columns=['Tenor','Unit','ATM','25D RR','25D BF','10D RR','10D BF']) #Dropping unnecessary columns\n",
    "\n",
    "    #print(df) #Uncomment this line if you want to see the processed dataframe\n",
    "    fig = go.Figure(data=[go.Surface(z=df[['10D','25D','50D','75D','90D']].values,\n",
    "                                     x=['10D','25D','50D','75D','90D'],\n",
    "                                     y=df['Date'].dt.strftime('%Y-%m-%d').values)])\n",
    "    fig.update_layout(title='FX Option Volatility Surface', autosize=True,\n",
    "                        scene = dict(\n",
    "                            xaxis_title='Delta',\n",
    "                            yaxis_title='Maturity Date',\n",
    "                            zaxis_title='Implied Volatility (%)'),\n",
    "                        )\n",
    "    #fig.show() #Uncomment this line if you want to see the plot in a separate window\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f85b0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data,i=-1,p=1):\n",
    "    from datetime import date,timedelta\n",
    "    import holidays\n",
    "    import pandas as pd\n",
    "    PricingDate = date.today() #Use todays date as the Pricing Date\n",
    "    #PricingDate = date(2025,5,19) # For testing currently\n",
    "    SDate = mfbd(PricingDate + timedelta(days=2),'US') #Calculating the Spot Start Date\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['Tenor','Unit','Rate']\n",
    "    i = int(i)\n",
    "    if i>-1:\n",
    "        df.iat[i,1]=df.iat[i,1]+0.0001*p\n",
    "        \n",
    "    df['MatDate'] = SDate \n",
    "    df['PmtDate'] = SDate\n",
    "\n",
    "    #Populate Maturity Date and Payment Date adjusting for pay delay\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        if row['Unit']=='d':\n",
    "            df.at[index,'MatDate'] = mfbd(row['MatDate'] + pd.offsets.DateOffset(days=row['Tenor']),'US')\n",
    "        elif row['Unit']=='w':\n",
    "            df.at[index,'MatDate'] = mfbd(row['MatDate'] + pd.offsets.DateOffset(weeks=row['Tenor']),'US')\n",
    "        elif row['Unit']=='m':\n",
    "            df.at[index,'MatDate'] = mfbd(row['MatDate'] + pd.offsets.DateOffset(months=row['Tenor']),'US')\n",
    "        elif row['Unit']=='y':\n",
    "            df.at[index,'MatDate'] = mfbd(row['MatDate'] + pd.offsets.DateOffset(years=row['Tenor']),'US')\n",
    "        \n",
    "        df.at[index,'PmtDate'] = mfbd(df.at[index,'MatDate'] + pd.offsets.DateOffset(days=2),'US') #SOFR Swaps have 2 days Payment Delay\n",
    "    \n",
    "    df['MatDate'] = pd.to_datetime(df['MatDate']).dt.date # To remove hh:mm:ss from Date\n",
    "    df['PmtDate'] = pd.to_datetime(df['PmtDate']).dt.date\n",
    "    df['DC'] = df['PmtDate'].diff(periods=1) #Compute Periodic day counts\n",
    "    \n",
    "    for i in range(0,15):\n",
    "        df.at[i,'DC']= pd.to_timedelta(df.at[i,'PmtDate']-SDate) #Compute DC value from Start Date for tenors upto 1 year\n",
    "    \n",
    "    \n",
    "    df['DC'] = pd.to_numeric(df['DC'].dt.days)\n",
    "    df['DC']=df['DC']/360 #Since Daycount is Act/360 for USD SOFR\n",
    " \n",
    "    import numpy as np\n",
    "    df['DF'] = 1.000000\n",
    " \n",
    "    SDate = mfbd(SDate,'US')\n",
    "\n",
    "\n",
    "    #Just testing, delete later\n",
    "    #for index,row in df.iterrows():\n",
    "    #    df.at[index,'DF'] = 1/(pow(1+row['Rate'],row['Year']))\n",
    "\n",
    "\n",
    "    #Compute actual Curve DFs for USD SOFR\n",
    "    #The for loop is massively simplified to solve a linear system of equations. Will write a full document on how this is calculated later. \n",
    "    # For queries in the interim email pushkars@myyahoo.com \n",
    "    dfdccumprodsum = 0\n",
    "    for index,row in df.iterrows():\n",
    "        if index < 14:\n",
    "            df.at[index,'DF'] = 1/(1+df.at[index,'Rate']*df.at[index,'DC'])\n",
    "        else:\n",
    "            df.at[index,'DF'] = (1 - df.at[index,'Rate']*dfdccumprodsum)/(1+df.at[index,'Rate']*df.at[index,'DC'])\n",
    "            dfdccumprodsum = dfdccumprodsum + df.at[index,'DC']*df.at[index,'DF']\n",
    "\n",
    "    #Compute Zeros for USD SOFR\n",
    "    # Please note that zeros requires an assumption of the approach. Here we are going to try and match\n",
    "    # it with that of bloomberg by assuming continuous compounding\n",
    "    # Different systems implement this bit in a different manner\n",
    "\n",
    "\n",
    "    df['Zero']=1.000000\n",
    "    \n",
    "    for index,row in df.iterrows():\n",
    "        #p = pd.to_timedelta(df.at[index,'PmtDate']-df.at[index,'MatDate'])\n",
    "        #t = float(p.days)/365 + df.at[index,'Year']\n",
    "        t = (df.at[index,'PmtDate'] - SDate).days/365 #Note this implementation is slightly different and less accurate as its \n",
    "        #dividing by 365 to give years which will create issues especially as we cross leap years. Will update in future iterations\n",
    "        #print(t)\n",
    "        df.at[index,'Zero'] = np.log(1/df.at[index,'DF'])/t\n",
    "\n",
    "    #Add 1 as Discount Factor for Spot Date in the Discount Factors Data Frame for US Rates \n",
    "    df.loc[-1] = [0.0,\"w\",0.0,SDate,SDate,0,1.00000,0]\n",
    "    df.index = df.index+1\n",
    "    df = df.sort_index()\n",
    "    \n",
    "        \n",
    "    #print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6847e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapfx(data,usdf,fcycode,divfactor=10000,i=-1,p=1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date,timedelta, datetime, time\n",
    "    import math \n",
    "    df=pd.DataFrame(data)\n",
    "    df.columns=['Tenor','Unit','Bid','Ask']\n",
    "    spotrate= (df.at[0,'Bid'] + df.at[0,'Ask'])/2\n",
    "    #df = df.drop(df.index[0]) #Drop the spot rate row\n",
    "    #df = df.reset_index(drop=True) #Reset index after dropping spot rate row\n",
    "   \n",
    "    df['OR']=spotrate + (df['Bid'] + df['Ask'])/ (2*divfactor) #Allows flexibility to use 100 for JPY and 10,000 by default for others\n",
    "    df.at[0,'OR']=spotrate  #Set the outright for spot rate row\n",
    "    #Set Pricing Date\n",
    "    PDate = date.today() #You can set it to desired pricing date\n",
    "    SDate = mfbd(PDate + timedelta(days=2),'US',fcycode) #Calculating the Spot Start Date basis code recieved \n",
    "    \n",
    "    #Generate Maturity Dates\n",
    "    df['Date'] = SDate\n",
    "    for index,row in df.iterrows():\n",
    "        if row['Unit']=='d':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(days=row['Tenor']),'US',fcycode)\n",
    "        elif row['Unit']=='w':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(weeks=row['Tenor']),'US',fcycode)\n",
    "        elif row['Unit']=='m':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(months=row['Tenor']),'US',fcycode)\n",
    "        elif row['Unit']=='y':\n",
    "            df.at[index,'Date'] = mfbd(row['Date'] + pd.offsets.DateOffset(years=row['Tenor']),'US',fcycode)\n",
    "\n",
    "\n",
    "    #This will require us to interpolate and we are creating a float column as we cant interpolate on dates directly\n",
    "    MyTime = time(0,0,0)\n",
    "    ref = pd.Timestamp.combine(SDate,MyTime)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Days']=(df['Date']-ref)/timedelta(days=1)\n",
    "    usdf['PmtDate'] = usdf['PmtDate'].astype(\"datetime64[ns]\")\n",
    "    usdf['Days']=(usdf['PmtDate']-datetime.combine(SDate,MyTime))/timedelta(days=1)\n",
    "    #print(usdf)\n",
    "    df['USDF']=np.interp(df['Days'],usdf['Days'],usdf['DF'])\n",
    "    if  fcycode == 'XECB' or fcycode == 'GB' or fcycode == 'AU':\n",
    "        df['FCYDF']=df['OR']*df['USDF']/spotrate\n",
    "    else:\n",
    "        df['FCYDF']=df['USDF']*spotrate/df['OR']    \n",
    "    \n",
    "    df['FCYYld']=(1/df['FCYDF']-1)*365/df['Days']\n",
    "    \n",
    "    df.at[0,'FCYYld'] = 0.0 #Override first yield with 0 as spot has no yield\n",
    "    \n",
    "    #This step overwrites the DFs and the Outrights with perturbed values if any\n",
    "    #i = int(i)\n",
    "    #if i>-1:\n",
    "    #    df.iat[i,6]=df.iat[i,6]+0.0001*p\n",
    "    #df['FCYDF']=1/(1+df['FCYYld']*df['Days']/365)\n",
    "    #df['OR']=spotrate *df['USDF']/df['FCYDF']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22250bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date,timedelta\n",
    "import holidays\n",
    "data = import_excel(\"Market Data.xlsx\",\"FXO\",\"b3:h17\")\n",
    "eursurf=volsurf(data,\"XECB\") #XECB is the code for TARGET Calendar\n",
    "data = import_excel('Market Data.xlsx','FXO','K3:M21')\n",
    "usdf=bootstrap(data)\n",
    "data = import_excel('Market Data.xlsx','FXO','C32:F54')\n",
    "eurdf=bootstrapfx(data,usdf,'XECB') #XECB is the code for TARGET Calendar\n",
    "\n",
    "\n",
    "#print(eurdf)\n",
    "#print(eursurf)\n",
    "\n",
    "#We now have both the vol surface and the discount factors for EUR. We can now price options using these inputs\n",
    "\n",
    "#We will now implement Black Scholes pricing for FX Options using the vol surface and discount factors generated above\n",
    "#Supporting only EUR/USD options for now. will extend later to other currencies \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c7098",
   "metadata": {},
   "source": [
    "This volLookup function is the most important piece of FX Option pricing and often not well understood. We tend to think of parmeters entered and the vols automatically generated in Bloomberg / other systems but there is a nuanced calculation behind this which is not so intuitive. \n",
    "\n",
    "I will try and explain a bit about it here \n",
    "\n",
    "To get the right vols given a strike we need to know the right Delta (Since the vols are quoted in delta terms)\n",
    "However, the formula for Delta is N(d1) which has vols as an input in the formula\n",
    "So this is an optimization problem which starts with a guess and then requires a numerical method to solve\n",
    "\n",
    "If you need further clarity or would like to discuss further please email pushkars@myyahoo.com and i'll try and revert as soon as possible\n",
    "\n",
    "Do also note that this implementation is not perfect but a close approximation\n",
    "\n",
    "FX Vols upto 1Y are typically ATMF but after that they are traded as DNS and DNS K does not equal ATMF K \n",
    "\n",
    "Actually DNS K has delta = 0.5 or 50% and ATMF is close to 50% \n",
    "\n",
    "For FXO Delta = N(D1) .. by the identity N(0)=0.5 you can equate D1 = 0 and figure it out easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a4457d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date,timedelta\n",
    "import holidays\n",
    "from scipy.stats import norm\n",
    "def volLookup(volsurf,dfs,style,K,D,Spot): #K is strike and D is delivery date\n",
    "    guess = 50 #Rough initial guess for Delta @ 50%\n",
    "    #This obtains the outright forward rate for the given delivery date\n",
    "    F=np.interp(pd.to_datetime(D).value,dfs['Date'].values.astype('datetime64[ns]').astype(np.int64),dfs['OR'].values)\n",
    "    T= (D-pd.Timestamp(Spot)).days/365\n",
    "    #print(T)\n",
    "    if style == 'Call':\n",
    "        #Convergence should be achieved in 3-5 iterations normally\n",
    "        for i in range(5):\n",
    "            #Step 1 - Get vol for the delta estimate\n",
    "            vol=interp_vol(volsurf,D,guess)\n",
    "            #Step 2 - Get Delta for the vol estimate\n",
    "            guess = norm.cdf((np.log(F/K)+(0.5*vol*vol*T))/(vol*np.sqrt(T)))*100\n",
    "            #print(\"Iteration \",i+1,\": Vol = \",vol,\", Delta = \",guess) #Uncomment this to see vol iterations\n",
    "    else:\n",
    "        #This is a Put instead of a call now \n",
    "        for i in range(5):\n",
    "            #Step 1 - Get vol for the delta estimate\n",
    "            vol=interp_vol(volsurf,D,100-guess) #This is because 25D Call = 75 Delta Put \n",
    "            #Step 2 - Get Delta for the vol estimate\n",
    "            guess = abs((norm.cdf((np.log(F/K)+(0.5*vol*vol*T))/(vol*np.sqrt(T)))-1)*100)\n",
    "            #print(\"Iteration \",i+1,\": Vol = \",vol,\", Delta = \",guess) #Uncomment this to see vol iterations\n",
    "    \n",
    "    #Lets just price the option as well using the Garman-Kohlhagen model\n",
    "    d1= (np.log(F/K)+(0.5*vol*vol*T))/(vol*np.sqrt(T))\n",
    "    d2 = d1 - (vol*np.sqrt(T))                                \n",
    "    rd = np.interp(pd.to_datetime(D).value,dfs['Date'].values.astype('datetime64[ns]').astype(np.int64),dfs['USDF'].values)\n",
    "    #Note rd above is not the interest rate but the USD discount factor itself , logic will have to be changed if pair is not eur or gbp\n",
    "    if style == 'Call':\n",
    "        # Price a call option\n",
    "        px = rd * (F*norm.cdf(d1)-K*norm.cdf(d2))       \n",
    "    else:\n",
    "        #Price a put option\n",
    "        px = rd *(K*norm.cdf(-d2)-F*norm.cdf(-d1))\n",
    "    #Return the converged volatility\n",
    "    #print(vol,\" \",px,\" \",guess)\n",
    "    return F,vol,px,guess\n",
    "            \n",
    "\n",
    "def interp_vol(df, target_date, target_delta):\n",
    "    \n",
    "    # Ensure Date is datetime\n",
    "    df = df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Delta columns (convert \"1D\"→1, \"10D\"→10, ..., \"99D\"→99)\n",
    "    delta_cols = [c for c in df.columns if c.endswith('D') and c != 'Date']\n",
    "    delta_values = np.array([int(c.replace('D','')) for c in delta_cols])\n",
    "    \n",
    "    # Interpolate each column on Date\n",
    "    # gives a single interpolated row for the exact date\n",
    "    df_date_indexed = df.set_index('Date')\n",
    "    interp_row = df_date_indexed.reindex(\n",
    "        df_date_indexed.index.union([target_date])\n",
    "    ).sort_index().interpolate(method='time').loc[target_date, delta_cols].values\n",
    "\n",
    "    #Interpolate along Delta axis\n",
    "    final_vol = np.interp(target_delta, delta_values, interp_row)\n",
    "\n",
    "    return final_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "297846f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pair Not CCY   Notional Style  B/S  Strike   Delivery       Vol  \\\n",
      "0  EUR/USD     EUR  1000000.0   Put  Buy   1.160 2026-01-15  0.056581   \n",
      "1  EUR/USD     EUR  2000000.0  Call  Buy   1.165 2026-09-25  0.063468   \n",
      "\n",
      "       Delta        Px       Fwd  \n",
      "0  43.747855  0.007819  1.163507  \n",
      "1  58.022673  0.032221  1.176719  \n"
     ]
    }
   ],
   "source": [
    "data = import_excel('Market Data.xlsx','FXOTrades','b2:h3') #Change to H3 later to price multiple trades\n",
    "fxoTrades=pd.DataFrame(data)\n",
    "fxoTrades.columns = ['Pair','Not CCY','Notional','Style','B/S','Strike','Delivery']\n",
    "fxoTrades['Vol']=0.0 #Initialize Dummy values for Vol\n",
    "fxoTrades['Delta']=0.0 #Initialize Dummy values for Vol\n",
    "fxoTrades['Px']=0.0 #Initialize Dummy values for Px\n",
    "#print(fxoTrades)\n",
    "for index,row in fxoTrades.iterrows():\n",
    "    if row['Pair']=='EUR/USD':\n",
    "        SDate = mfbd(date.today() + timedelta(days=2),'US','XECB') #Using a fixed pricing date for testing\n",
    "        F,vol,px,delta=volLookup(eursurf,eurdf,row['Style'],row['Strike'],row['Delivery'],SDate)\n",
    "        fxoTrades.loc[index,'Fwd']=F\n",
    "        fxoTrades.loc[index,'Vol']=vol\n",
    "        fxoTrades.loc[index,'Delta']=delta\n",
    "        fxoTrades.loc[index,'Px']=px\n",
    "\n",
    "print(fxoTrades)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812e8d4f",
   "metadata": {},
   "source": [
    "![alternative text](./FXO1.png)\n",
    "![alternative text](./FXO2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271d746",
   "metadata": {},
   "source": [
    "The numbers are fairly close Please note that i had to type in market data manually and then price in bloomberg which is why there is a difference. This gap will almost vanish if i align the data but that defeats the whole purpose of replication"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
